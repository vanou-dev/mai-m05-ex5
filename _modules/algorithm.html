

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>algorithm &mdash; logreg_iris 1.0.0 documentation</title>
  

  
  
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/graphviz.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> logreg_iris
          

          
            
            <img src="../_static/logo.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                1.0.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guide.html">User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../troubleshooting.html">Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../py_api.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../license.html">Licensing</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">logreg_iris</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="index.html">Module code</a> &raquo;</li>
        
      <li>algorithm</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for algorithm</h1><div class="highlight"><pre>
<span></span><span class="ch">#!/usr/bin/env python</span>
<span class="c1"># coding=utf-8</span>

<span class="kn">import</span> <span class="nn">logging</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">()</span>

<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">scipy.optimize</span>


<div class="viewcode-block" id="make_labels"><a class="viewcode-back" href="../py_api.html#algorithm.make_labels">[docs]</a><span class="k">def</span> <span class="nf">make_labels</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Helper function that generates a single 1D array with labels which</span>
<span class="sd">    are good targets for stock logistic regression.</span>


<span class="sd">    Parameters</span>
<span class="sd">    ==========</span>

<span class="sd">    X : numpy.ndarray</span>

<span class="sd">        The input data matrix. This must be an array with 3 dimensions or an</span>
<span class="sd">        iterable containing 2 arrays with 2 dimensions each. Each correspond to</span>
<span class="sd">        the data for one of the two classes, every row corresponds to one</span>
<span class="sd">        example of the data set, every column, one different feature.</span>


<span class="sd">    Returns</span>
<span class="sd">    =======</span>

<span class="sd">    labels : numpy.ndarray</span>
<span class="sd">        With a single dimension, containing suitable labels for all rows and</span>
<span class="sd">        for all classes defined in X (depth).</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="n">numpy</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span>
        <span class="p">[</span><span class="n">k</span> <span class="o">*</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">))]</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="Machine"><a class="viewcode-back" href="../py_api.html#algorithm.Machine">[docs]</a><span class="k">class</span> <span class="nc">Machine</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;A class to handle all run-time aspects for Logistic Regression</span>

<span class="sd">    Parameters</span>
<span class="sd">    ==========</span>

<span class="sd">    theta : numpy.ndarray</span>
<span class="sd">        A set of parameters for the Logistic Regression model. This must be an</span>
<span class="sd">        iterable (or numpy array) with all parameters for the model, including</span>
<span class="sd">        the bias term, which must be on entry 0 (the first entry at the</span>
<span class="sd">        iterable).</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">theta</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Spits out the hypothesis given the data.</span>


<span class="sd">        Parameters</span>
<span class="sd">        ==========</span>

<span class="sd">        X : numpy.ndarray</span>

<span class="sd">            The input data matrix. This must be an array with 2 dimensions.</span>
<span class="sd">            Every row corresponds to one example of the data set, every column,</span>
<span class="sd">            one different feature.</span>


<span class="sd">        Returns</span>
<span class="sd">        =======</span>

<span class="sd">        hypothesis : numpy.ndarray</span>
<span class="sd">            A 1D array with as many entries as rows in the input 2D array</span>
<span class="sd">            ``X``, representing g(x), the sigmoidal hypothesis.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">Xp</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">numpy</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">X</span><span class="p">))</span>  <span class="c1"># add bias term</span>
        <span class="k">return</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">numpy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">numpy</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Xp</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">)))</span>

<div class="viewcode-block" id="Machine.predict"><a class="viewcode-back" href="../py_api.html#algorithm.Machine.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Predicts the class of each row of X</span>


<span class="sd">        Parameters</span>
<span class="sd">        ==========</span>

<span class="sd">        X : numpy.ndarray</span>
<span class="sd">            The input data matrix. This must be an array with 2 dimensions.</span>
<span class="sd">            Every row corresponds to one example of the data set, every column,</span>
<span class="sd">            one different feature.</span>


<span class="sd">        Returns</span>
<span class="sd">        =======</span>

<span class="sd">        predictions : numpy.ndarray</span>
<span class="sd">            A 1D array with as many entries as rows in the input 2D array</span>
<span class="sd">            ``X``, representing g(x), the class predictions for the current</span>
<span class="sd">            machine.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">retval</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">retval</span><span class="p">[</span><span class="n">retval</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">retval</span><span class="p">[</span><span class="n">retval</span> <span class="o">&gt;=</span> <span class="mf">0.5</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
        <span class="k">return</span> <span class="n">retval</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span></div>

<div class="viewcode-block" id="Machine.J"><a class="viewcode-back" href="../py_api.html#algorithm.Machine.J">[docs]</a>    <span class="k">def</span> <span class="nf">J</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">regularizer</span><span class="o">=</span><span class="mf">0.0</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculates the logistic regression cost</span>

<span class="sd">        Parameters</span>
<span class="sd">        ==========</span>

<span class="sd">        X : numpy.ndarray</span>

<span class="sd">            The input data matrix. This must be an array with 3 dimensions or an</span>
<span class="sd">            iterable containing 2 numpy.ndarrays with 2 dimensions each. Each</span>
<span class="sd">            correspond to the data for one of the two classes, every row</span>
<span class="sd">            corresponds to one example of the data set, every column, one</span>
<span class="sd">            different feature.</span>

<span class="sd">        regularizer : float</span>
<span class="sd">            The regularization parameter</span>


<span class="sd">        Returns</span>
<span class="sd">        =======</span>

<span class="sd">        cost : float</span>
<span class="sd">            The averaged (regularized) cost for the whole dataset</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">h</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="bp">self</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="p">])</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)])</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">make_labels</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="n">logh</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">h</span><span class="p">))</span>
        <span class="n">log1h</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">h</span><span class="p">))</span>
        <span class="n">regularization_term</span> <span class="o">=</span> <span class="n">regularizer</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">main_term</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="n">y</span> <span class="o">*</span> <span class="n">logh</span> <span class="o">+</span> <span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="n">log1h</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">main_term</span> <span class="o">+</span> <span class="n">regularization_term</span></div>

<div class="viewcode-block" id="Machine.dJ"><a class="viewcode-back" href="../py_api.html#algorithm.Machine.dJ">[docs]</a>    <span class="k">def</span> <span class="nf">dJ</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">regularizer</span><span class="o">=</span><span class="mf">0.0</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculates the logistic regression first derivative of the cost w.r.t.</span>
<span class="sd">        each parameter theta</span>


<span class="sd">        Parameters</span>
<span class="sd">        ==========</span>

<span class="sd">        X : numpy.ndarray</span>
<span class="sd">            The input data matrix. This must be an array with 3 dimensions or</span>
<span class="sd">            an iterable containing 2 arrays with 2 dimensions each. Each</span>
<span class="sd">            correspond to the data for one of the two classes, every row</span>
<span class="sd">            corresponds to one example of the data set, every column, one</span>
<span class="sd">            different feature.</span>

<span class="sd">        regularizer : float</span>
<span class="sd">            The regularization parameter, if the solution should be regularized.</span>


<span class="sd">        Returns</span>
<span class="sd">        =======</span>

<span class="sd">        grad : numpy.ndarray</span>
<span class="sd">            A 1D array with as many entries as columns on the input matrix</span>
<span class="sd">            ``X`` plus 1 (the bias term). It denotes the average gradient of</span>
<span class="sd">            the cost w.r.t. to each machine parameter theta.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">Xflat</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">X</span><span class="p">])</span>
        <span class="n">Xp</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">numpy</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">Xflat</span><span class="p">),</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">Xflat</span><span class="p">))</span>  <span class="c1"># add bias term</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">make_labels</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="n">retval</span> <span class="o">=</span> <span class="p">((</span><span class="bp">self</span><span class="p">(</span><span class="n">Xflat</span><span class="p">)</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="n">Xp</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">retval</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">+=</span> <span class="p">(</span><span class="n">regularizer</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">retval</span></div></div>


<div class="viewcode-block" id="Trainer"><a class="viewcode-back" href="../py_api.html#algorithm.Trainer">[docs]</a><span class="k">class</span> <span class="nc">Trainer</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;A class to handle all training aspects for Logistic Regression</span>


<span class="sd">    Parameters</span>
<span class="sd">    ==========</span>

<span class="sd">    regularizer : float</span>
<span class="sd">        The regularization parameter</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">regularizer</span><span class="o">=</span><span class="mf">0.0</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">regularizer</span> <span class="o">=</span> <span class="n">regularizer</span>

<div class="viewcode-block" id="Trainer.J"><a class="viewcode-back" href="../py_api.html#algorithm.Trainer.J">[docs]</a>    <span class="k">def</span> <span class="nf">J</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">machine</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculates the vectorized cost *J*.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">machine</span><span class="o">.</span><span class="n">theta</span> <span class="o">=</span> <span class="n">theta</span>
        <span class="k">return</span> <span class="n">machine</span><span class="o">.</span><span class="n">J</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">regularizer</span><span class="p">)</span></div>

<div class="viewcode-block" id="Trainer.dJ"><a class="viewcode-back" href="../py_api.html#algorithm.Trainer.dJ">[docs]</a>    <span class="k">def</span> <span class="nf">dJ</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">machine</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculates the vectorized partial derivative of the cost *J* w.r.t. to</span>
<span class="sd">        **all** :math:`\theta`&#39;s. Use the training dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">machine</span><span class="o">.</span><span class="n">theta</span> <span class="o">=</span> <span class="n">theta</span>
        <span class="k">return</span> <span class="n">machine</span><span class="o">.</span><span class="n">dJ</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">regularizer</span><span class="p">)</span></div>

<div class="viewcode-block" id="Trainer.train"><a class="viewcode-back" href="../py_api.html#algorithm.Trainer.train">[docs]</a>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Optimizes the machine parameters to fit the input data, using</span>
<span class="sd">        ``scipy.optimize.fmin_l_bfgs_b``.</span>


<span class="sd">        Parameters</span>
<span class="sd">        ==========</span>

<span class="sd">        X : numpy.ndarray</span>
<span class="sd">            The input data matrix. This must be an array with 3 dimensions or</span>
<span class="sd">            an iterable containing 2 arrays with 2 dimensions each.  Each</span>
<span class="sd">            correspond to the data for one of the two classes, every row</span>
<span class="sd">            corresponds to one example of the data set, every column, one</span>
<span class="sd">            different feature.</span>


<span class="sd">        Returns</span>
<span class="sd">        =======</span>

<span class="sd">        machine : Machine</span>
<span class="sd">            A trained machine.</span>


<span class="sd">        Raises</span>
<span class="sd">        ======</span>

<span class="sd">        RuntimeError</span>
<span class="sd">            In case problems exist with the design matrix ``X`` or with</span>
<span class="sd">            convergence.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># check data dimensionality if not organized in a matrix</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="n">baseline</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">X</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">k</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="n">baseline</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                        <span class="s2">&quot;Mismatch on the dimensionality of input `X`&quot;</span>
                    <span class="p">)</span>

        <span class="c1"># prepare the machine</span>
        <span class="n">theta0</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># include bias terms</span>
        <span class="n">machine</span> <span class="o">=</span> <span class="n">Machine</span><span class="p">(</span><span class="n">theta0</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Settings:&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;  * initial guess = </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">theta0</span><span class="p">])</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;  * cost (J) = </span><span class="si">%g</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">machine</span><span class="o">.</span><span class="n">J</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">regularizer</span><span class="p">))</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Training using scipy.optimize.fmin_l_bfgs_b()...&quot;</span><span class="p">)</span>

        <span class="c1"># Fill in the right parameters so that the minimization can take place</span>
        <span class="n">theta</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">d</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">optimize</span><span class="o">.</span><span class="n">fmin_l_bfgs_b</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">J</span><span class="p">,</span>
            <span class="n">theta0</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dJ</span><span class="p">,</span>
            <span class="p">(</span><span class="n">machine</span><span class="p">,</span> <span class="n">X</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">d</span><span class="p">[</span><span class="s2">&quot;warnflag&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;** LBFGS converged successfuly **&quot;</span><span class="p">)</span>
            <span class="n">machine</span><span class="o">.</span><span class="n">theta</span> <span class="o">=</span> <span class="n">theta</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Final settings:&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;  * theta = </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">theta</span><span class="p">])</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;  * cost (J) = </span><span class="si">%g</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">cost</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">machine</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">message</span> <span class="o">=</span> <span class="s2">&quot;LBFGS did **not** converged:&quot;</span>
            <span class="k">if</span> <span class="n">d</span><span class="p">[</span><span class="s2">&quot;warnflag&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">message</span> <span class="o">+=</span> <span class="s2">&quot; Too many function evaluations&quot;</span>
            <span class="k">elif</span> <span class="n">d</span><span class="p">[</span><span class="s2">&quot;warnflag&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">message</span> <span class="o">+=</span> <span class="s2">&quot;  </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">d</span><span class="p">[</span><span class="s2">&quot;task&quot;</span><span class="p">]</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="n">message</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="MultiClassMachine"><a class="viewcode-back" href="../py_api.html#algorithm.MultiClassMachine">[docs]</a><span class="k">class</span> <span class="nc">MultiClassMachine</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;A class to handle all run-time aspects for Multiclass Log. Regression</span>


<span class="sd">    Parameters</span>
<span class="sd">    ==========</span>

<span class="sd">    machines : :py:class:`list` or :py:class:`tuple`</span>
<span class="sd">        An iterable over any number of machines that will be stored.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">machines</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">machines</span> <span class="o">=</span> <span class="n">machines</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Spits out the hypothesis for each machine given the data</span>


<span class="sd">        Parameters</span>
<span class="sd">        ==========</span>

<span class="sd">        X : numpy.ndarray</span>
<span class="sd">            The input data matrix. This must be an array with 2 dimensions.</span>
<span class="sd">            Every row corresponds to one example of the data set, every column,</span>
<span class="sd">            one different feature.</span>


<span class="sd">        Returns</span>
<span class="sd">        =======</span>

<span class="sd">        hypothesis : numpy.ndarray</span>
<span class="sd">            A 2D array with as many entries as rows in the input 2D</span>
<span class="sd">            array ``X``, representing g(x), the sigmoidal hypothesis. Each</span>
<span class="sd">            column on the output array represents the output of one of the</span>
<span class="sd">            logistic regression machines in this</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">numpy</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">m</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">machines</span><span class="p">])</span><span class="o">.</span><span class="n">T</span>

<div class="viewcode-block" id="MultiClassMachine.predict"><a class="viewcode-back" href="../py_api.html#algorithm.MultiClassMachine.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Predicts the class of each row of X</span>


<span class="sd">        Parameters</span>
<span class="sd">        ==========</span>

<span class="sd">        X : numpy.ndarray</span>
<span class="sd">            The input data matrix. This must be an array with 3 dimensions or</span>
<span class="sd">            an iterable containing 2 arrays with 2 dimensions each.  Each</span>
<span class="sd">            correspond to the data for one of the two classes, every row</span>
<span class="sd">            corresponds to one example of the data set, every column, one</span>
<span class="sd">            different feature.</span>


<span class="sd">        Returns</span>
<span class="sd">        =======</span>

<span class="sd">        predictions : numpy.ndarray</span>
<span class="sd">            A 1D array with as many entries as rows in the input 2D array</span>
<span class="sd">            ``X``, representing g(x), the class predictions for the current</span>
<span class="sd">            machine.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="bp">self</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="MultiClassTrainer"><a class="viewcode-back" href="../py_api.html#algorithm.MultiClassTrainer">[docs]</a><span class="k">class</span> <span class="nc">MultiClassTrainer</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;A class to handle all training aspects for Multiclass Log. Regression</span>


<span class="sd">    Parameters</span>
<span class="sd">    ==========</span>

<span class="sd">    regularizer : float</span>
<span class="sd">        The regularization parameter</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">regularizer</span><span class="o">=</span><span class="mf">0.0</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">regularizer</span> <span class="o">=</span> <span class="n">regularizer</span>

<div class="viewcode-block" id="MultiClassTrainer.train"><a class="viewcode-back" href="../py_api.html#algorithm.MultiClassTrainer.train">[docs]</a>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Trains multiple logistic regression classifiers to handle the multiclass</span>
<span class="sd">        problem posed by ``X``.</span>


<span class="sd">        Parameters</span>
<span class="sd">        ==========</span>

<span class="sd">        X : numpy.ndarray</span>
<span class="sd">            The input data matrix. This must be an array with 3 dimensions or</span>
<span class="sd">            an iterable containing 2 arrays with 2 dimensions each.  Each</span>
<span class="sd">            correspond to the data for one of the input classes, every row</span>
<span class="sd">            corresponds to one example of the data set, every column, one</span>
<span class="sd">            different feature.</span>


<span class="sd">        Returns</span>
<span class="sd">        =======</span>

<span class="sd">        machine : Machine</span>
<span class="sd">            A trained multiclass machine.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">_trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">regularizer</span><span class="p">)</span>

        <span class="k">if</span> <span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span>
        <span class="p">):</span>  <span class="c1"># trains and returns a single logistic regression classifer</span>

            <span class="k">return</span> <span class="n">_trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>  <span class="c1"># trains and returns a multi-class logistic regression classifier</span>

            <span class="c1"># use one-versus-all strategy</span>
            <span class="n">machines</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)):</span>
                <span class="n">NC_range</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">k</span><span class="p">))</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)))</span>
                <span class="n">Xp</span> <span class="o">=</span> <span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">NC_range</span><span class="p">]),</span> <span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="p">]]</span>
                <span class="n">machines</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">Xp</span><span class="p">))</span>

            <span class="k">return</span> <span class="n">MultiClassMachine</span><span class="p">(</span><span class="n">machines</span><span class="p">)</span></div></div>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, Idiap Research Institute

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>